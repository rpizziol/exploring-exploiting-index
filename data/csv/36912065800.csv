doi,citedby_count,description,author_names,author_ids
10.1103/PhysRevE.108.054301,0,"At least two different approaches to define and solve statistical models for the analysis of economic systems exist: the typical, econometric one, interpreting the gravity model specification as the expected link weight of an arbitrary probability distribution, and the one rooted in statistical physics, constructing maximum-entropy distributions constrained to satisfy certain network properties. In a couple of recent companion papers, they have been successfully integrated within the framework induced by the constrained minimization of the Kullback-Leibler divergence: specifically, two broad classes of models have been devised, i.e., the integrated and conditional ones, defined by different, probabilistic rules to place links, load them with weights and turn them into proper, econometric prescriptions. Still, the recipes adopted by the two approaches to estimate the parameters entering into the definition of each model differ. In econometrics, a likelihood that decouples the binary and weighted parts of a model, treating a network as deterministic, is typically maximized; to restore its random character, two alternatives exist: either solving the likelihood maximization on each configuration of the ensemble and taking the average of the parameters afterwards or taking the average of the likelihood function and maximizing the latter one. The difference between these approaches lies in the order in which the operations of averaging and maximization are taken - a difference that is reminiscent of the quenched and annealed ways of averaging out the disorder in spin glasses. The results of the present contribution, devoted to comparing these recipes in the case of continuous, conditional network models, indicate that the annealed estimation recipe represents the best alternative to the deterministic one.","Di Vece, Marzio;Garlaschelli, Diego;Squartini, Tiziano",57845258900;6603265005;36912065800
10.1007/978-3-031-21127-0_8,1,"One of the main dimensions characterizing the unfolding of opinion formation processes in social debates is the degree of open-mindedness of the involved population. Opinion dynamic modeling studies have tried to capture such a peculiar expression of individuals’ personalities and relate it to emerging phenomena like polarization, radicalization, and ideology fragmentation. However, one of their major limitations lies in the strong assumptions they make on the initial distribution of such characteristics, often fixed so as to satisfy a normality hypothesis. Here we propose a data-driven methodology to estimate users’ open-mindedness from online discussion data. Our analysis—focused on the political discussion taking place on Reddit during the first two years of the Trump presidency—unveils the existence of statistically diverse distributions of open-mindedness in annotated sub-populations (i.e., Republicans, Democrats, and Moderates/Neutrals). Moreover, such distributions appear to be stable across time and generated by individual users’ behaviors that remain consistent and underdispersed.","Pansanella, Valentina;Morini, Virginia;Squartini, Tiziano;Rossetti, Giulio",57405087800;57218952243;36912065800;55002008000
10.1016/j.chaos.2022.112958,1,"In the study of economic networks, econometric approaches interpret the traditional Gravity Model specification as the expected link weight coming from a probability distribution whose functional form can be chosen arbitrarily, while statistical-physics approaches construct maximum-entropy distributions of weighted graphs, constrained to satisfy a given set of measurable network properties. In a recent, companion paper, we integrated the two approaches and applied them to the World Trade Web, i.e. the network of international trade among world countries. While the companion paper dealt only with discrete-valued link weights, the present paper extends the theoretical framework to continuous-valued link weights. In particular, we construct two broad classes of maximum-entropy models, namely the integrated and the conditional ones, defined by different criteria to derive and combine the probabilistic rules for placing links and loading them with weights. In the integrated models, both rules follow from a single, constrained optimization of the continuous Kullback–Leibler divergence; in the conditional models, the two rules are disentangled and the functional form of the weight distribution follows from a conditional, optimization procedure. After deriving the general functional form of the two classes, we turn each of them into a proper family of econometric models via a suitable identification of the econometric function relating the corresponding, expected link weights to macroeconomic factors. After testing the two classes of models on World Trade Web data, we discuss their strengths and weaknesses.","Di Vece, Marzio;Garlaschelli, Diego;Squartini, Tiziano",57845258900;6603265005;36912065800
10.1038/s41598-022-13996-3,3,"Recent crises have shown that the knowledge of the structure of input–output networks, at the firm level, is crucial when studying economic resilience from the microscopic point of view of firms that try to rewire their connections under supply and demand constraints. Unfortunately, empirical inter-firm network data are protected by confidentiality, hence rarely accessible. The available methods for network reconstruction from partial information treat all pairs of nodes as potentially interacting, thereby overestimating the rewiring capabilities of the system and the implied resilience. Here, we use two big data sets of transactions in the Netherlands to represent a large portion of the Dutch inter-firm network and document its properties. We, then, introduce a generalized maximum-entropy reconstruction method that preserves the production function of each firm in the data, i.e. the input and output flows of each node for each product type. We confirm that the new method becomes increasingly more reliable in reconstructing the empirical network as a finer product resolution is considered and can, therefore, be used as a realistic generative model of inter-firm networks with fine production constraints. Moreover, the likelihood of the model directly enumerates the number of alternative network configurations that leave each firm in its current production state, thereby estimating the reduction in the rewiring capability of the system implied by the observed input–output constraints.","Ialongo, Leonardo Niccolò;de Valk, Camille;Marchese, Emiliano;Jansen, Fabian;Zmarrou, Hicham;Squartini, Tiziano;Garlaschelli, Diego",57372953400;57372978700;57222183900;57372880300;22137270100;36912065800;6603265005
10.1038/s42005-022-00890-7,2,"The importance of identifying mesoscale structures in complex networks can be hardly overestimated. So far, much attention has been devoted to detect modular and bimodular structures on binary networks. This effort has led to the definition of a framework based upon the score function called ‘surprise’, i.e. a p-value that can be assigned to any given partition of nodes. Hereby, we make a step further and extend the entire framework to the weighted case: six variants of surprise, induced by just as many variants of the hypergeometric distribution, are, thus, considered. As a result, a general, statistically grounded approach for detecting mesoscale network structures via a unified, suprise-based framework is presented. To illustrate its performances, both synthetic benchmarks and real-world configurations are considered. Moreover, we attach to the paper a Python code implementing all variants of surprise discussed in the present manuscript.","Marchese, Emiliano;Caldarelli, Guido;Squartini, Tiziano",57222183900;55139905100;36912065800
10.1016/j.chaos.2022.112620,10,"The Bitcoin Lightning Network (BLN) was launched in 2018 to scale up the number of transactions between Bitcoin owners. Although several contributions concerning the analysis of the BLN binary structure have recently appeared in the literature, the properties of its weighted counterpart are still largely unknown. The present contribution aims at filling this gap, by considering the Bitcoin Lightning Network over a period of 18 months, ranging from 12th January 2018 to 17th July 2019, and focusing on its weighted, undirected, daily snapshot representation - each weight representing the total capacity of the channels the two involved nodes have established on a given temporal snapshot. As the study of the BLN weighted structural properties reveals, it is becoming increasingly ‘centralized’ at different levels, just as its binary counterpart: (1) the Nakamoto coefficient shows that the percentage of nodes whose degrees/strengths ‘enclose’ the 51% of the total number of links/total weight is rapidly decreasing; (2) the Gini coefficient confirms that several weighted centrality measures are becoming increasingly unevenly distributed; (3) the weighted BLN topology is becoming increasingly compatible with a core–periphery structure, with the largest nodes ‘by strength’ constituting the core of such a network, whose size keeps shrinking as the BLN evolves. Further inspection of the resilience of the weighted BLN shows that removing such hubs leads to the network fragmentation into many components, an evidence indicating potential security threats — as the ones represented by the so called ‘split attacks’.","Lin, Jian Hong;Marchese, Emiliano;Tessone, Claudio J.;Squartini, Tiziano",56996303000;57222183900;6602779977;36912065800
10.1103/PhysRevResearch.4.033105,2,"The World Trade Web (WTW) is the network of international trade relationships among world countries. Characterizing both the local link weights (observed trade volumes) and the global network structure (large-scale topology) of the WTW via a single model is still an open issue. While the traditional Gravity Model (GM) successfully replicates the observed trade volumes by employing macroeconomic properties such as GDP and geographic distance, it unfortunately predicts a fully connected network, returning a completely unrealistic topology of the WTW. To overcome this problem, two different classes of models have been introduced in econometrics and statistical physics. Econometric approaches interpret the traditional GM as the expected value of a probability distribution that can be chosen largely arbitrarily and tested against alternative distributions. Statistical physics approaches construct maximum-entropy probability distributions of (weighted) graphs from a chosen set of measurable, structural constraints and test distributions resulting from different constraints. Here we compare and integrate the two approaches by considering a class of maximum-entropy models that can incorporate macroeconomic properties used in standard econometric models. We find that the integrated approach achieves an overall better performance than the purely econometric one. These results suggest that the maximum-entropy construction can serve as a viable econometric framework wherein extensive and intensive margins can be separately controlled for, by combining topological constraints and dyadic macroeconomic variables.","Di Vece, Marzio;Garlaschelli, Diego;Squartini, Tiziano",57845258900;6603265005;36912065800
10.1140/epjds/s13688-021-00301-x,10,"The Covid-19 pandemic has had a deep impact on the lives of the entire world population, inducing a participated societal debate. As in other contexts, the debate has been the subject of several d/misinformation campaigns; in a quite unprecedented fashion, however, the presence of false information has seriously put at risk the public health. In this sense, detecting the presence of malicious narratives and identifying the kinds of users that are more prone to spread them represent the first step to limit the persistence of the former ones. In the present paper we analyse the semantic network observed on Twitter during the first Italian lockdown (induced by the hashtags contained in approximately 1.5 millions tweets published between the 23rd of March 2020 and the 23rd of April 2020) and study the extent to which various discursive communities are exposed to d/misinformation arguments. As observed in other studies, the recovered discursive communities largely overlap with traditional political parties, even if the debated topics concern different facets of the management of the pandemic. Although the themes directly related to d/misinformation are a minority of those discussed within our semantic networks, their popularity is unevenly distributed among the various discursive communities.","Mattei, Mattia;Caldarelli, Guido;Squartini, Tiziano;Saracco, Fabio",57224908706;55139905100;36912065800;36344077800
10.1038/s41598-021-93830-4,13,"Exponential Random Graph Models (ERGMs) have gained increasing popularity over the years. Rooted into statistical physics, the ERGMs framework has been successfully employed for reconstructing networks, detecting statistically significant patterns in graphs, counting networked configurations with given properties. From a technical point of view, the ERGMs workflow is defined by two subsequent optimization steps: the first one concerns the maximization of Shannon entropy and leads to identify the functional form of the ensemble probability distribution that is maximally non-committal with respect to the missing information; the second one concerns the maximization of the likelihood function induced by this probability distribution and leads to its numerical determination. This second step translates into the resolution of a system of O(N) non-linear, coupled equations (with N being the total number of nodes of the network under analysis), a problem that is affected by three main issues, i.e. accuracy, speed and scalability. The present paper aims at addressing these problems by comparing the performance of three algorithms (i.e. Newton’s method, a quasi-Newton method and a recently-proposed fixed-point recipe) in solving several ERGMs, defined by binary and weighted constraints in both a directed and an undirected fashion. While Newton’s method performs best for relatively little networks, the fixed-point recipe is to be preferred when large configurations are considered, as it ensures convergence to the solution within seconds for networks with hundreds of thousands of nodes (e.g. the Internet, Bitcoin). We attach to the paper a Python code implementing the three aforementioned algorithms on all the ERGMs considered in the present work.","Vallarano, Nicolò;Bruno, Matteo;Marchese, Emiliano;Trapani, Giuseppe;Saracco, Fabio;Cimini, Giulio;Zanon, Mario;Squartini, Tiziano",57219510828;57204464985;57222183900;57222186750;36344077800;36781874700;55375650900;36912065800
10.1038/s41598-021-92337-2,16,"Social media play a key role in shaping citizens’ political opinion. According to the Eurobarometer, the percentage of EU citizens employing online social networks on a daily basis has increased from 18% in 2010 to 48% in 2019. The entwinement between social media and the unfolding of political dynamics has motivated the interest of researchers for the analysis of users online behavior—with particular emphasis on group polarization during debates and echo-chambers formation. In this context, semantic aspects have remained largely under-explored. In this paper, we aim at filling this gap by adopting a two-steps approach. First, we identify the discursive communities animating the political debate in the run up of the 2018 Italian Elections as groups of users with a significantly-similar retweeting behavior. Second, we study the mechanisms that shape their internal discussions by monitoring, on a daily basis, the structural evolution of the semantic networks they induce. Above and beyond specifying the semantic peculiarities of the Italian electoral competition, our approach innovates studies of online political discussions in two main ways. On the one hand, it grounds semantic analysis within users’ behaviors by implementing a method, rooted in statistical theory, that guarantees that our inference of socio-semantic structures is not biased by any unsupported assumption about missing information; on the other, it is completely automated as it does not rest upon any manual labelling (either based on the users’ features or on their sharing patterns). These elements make our method applicable to any Twitter discussion regardless of the language or the topic addressed.","Radicioni, Tommaso;Saracco, Fabio;Pavan, Elena;Squartini, Tiziano",57219623287;36344077800;36057321600;36912065800
10.1371/journal.pone.0256705,6,"The huge amount of data made available by the massive usage of social media has opened up the unprecedented possibility to carry out a data-driven study of political processes. While particular attention has been paid to phenomena like elite and mass polarization during online debates and echo-chambers formation, the interplay between online partisanship and framing practices, jointly sustaining adversarial dynamics, still remains overlooked. With the present paper, we carry out a socio-semantic analysis of the debate about migration policies observed on the Italian Twittersphere, across the period May-November 2019. As regards the social analysis, our methodology allows us to extract relevant information about the political orientation of the communities of users—hereby called partisan communities—without resorting upon any external information. Remarkably, our community detection technique is sensitive enough to clearly highlight the dynamics characterizing the relationship among different political forces. As regards the semantic analysis, our networks of hashtags display a mesoscale structure organized in a core-periphery fashion, across the entire observation period. Taken altogether, our results point at different, yet overlapping, trajectories of conflict played out using migration issues as a backdrop. A first line opposes communities discussing substantively of migration to communities approaching this issue just to fuel hostility against political opponents; within the second line, a mechanism of distancing between partisan communities reflects shifting political alliances within the governmental coalition. Ultimately, our results contribute to shed light on the complexity of the Italian political context characterized by multiple poles of partisan alignment.","Radicioni, Tommaso;Squartini, Tiziano;Pavan, Elena;Saracco, Fabio",57219623287;36912065800;36057321600;36344077800
10.1088/1367-2630/ac122d,0,"The bitcoin lightning network (BLN), a so-called 'second layer' payment protocol, was launched in 2018 to scale up the number of transactions between bitcoin owners. In this paper, we analyse the structure of the BLN over a period of 18 months, ranging from 12th January 2018 to 17th July 2019, at the end of which the network has reached 8.216 users, 122.517 active channels and 2.732,5 transacted bitcoins. Here, we consider three representations of the BLN: the daily snapshot one, the weekly snapshot one and the daily-block snapshot one. By studying the topological properties of the binary and weighted versions of the three representations above, we find that the total volume of transacted bitcoins approximately grows as the square of the network size; however, despite the huge activity characterising the BLN, the bitcoins distribution is very unequal: the average Gini coefficient of the node strengths (computed across the entire history of the Bitcoin Lightning Network) is, in fact, ≃0.88 causing the 10% (50%) of the nodes to hold the 80% (99%) of the bitcoins at stake in the BLN (on average, across the entire period). This concentration brings up the question of which minimalist network model allows us to explain the network topological structure. Like for other economic systems, we hypothesise that local properties of nodes, like the degree, ultimately determine part of its characteristics. Therefore, we have tested the goodness of the undirected binary configuration model (UBCM) in reproducing the structural features of the BLN: the UBCM recovers the disassortative and the hierarchical character of the BLN but underestimates the centrality of nodes; this suggests that the BLN is becoming an increasingly centralised network, more and more compatible with a core-periphery structure. Further inspection of the resilience of the BLN shows that removing hubs leads to the collapse of the network into many components, an evidence suggesting that this network may be a target for the so-called split attacks.","Lin, Jian Hong;Primicerio, Kevin;Squartini, Tiziano;Decker, Christian;Tessone, Claudio J.",56996303000;57192640151;36912065800;57196776143;6602779977
10.1038/s42254-021-00322-5,65,"As the total value of the global financial market outgrew the value of the real economy, financial institutions created a global web of interactions that embodies systemic risks. Understanding these networks requires new theoretical approaches and new tools for quantitative analysis. Statistical physics contributed significantly to this challenge by developing new metrics and models for the study of financial network structure, dynamics, and stability and instability. In this Review, we introduce network representations originating from different financial relationships, including direct interactions such as loans, similarities such as co-ownership and higher-order relations such as contracts involving several parties (for example, credit default swaps) or multilayer connections (possibly extending to the real economy). We then review models of financial contagion capturing the diffusion and impact of shocks across each of these systems. We also discuss different notions of ‘equilibrium’ in economics and statistical physics, and how they lead to maximum entropy ensembles of graphs, providing tools for financial network inference and the identification of early-warning signals of system-wide instabilities.","Bardoscia, Marco;Barucca, Paolo;Battiston, Stefano;Caccioli, Fabio;Cimini, Giulio;Garlaschelli, Diego;Saracco, Fabio;Squartini, Tiziano;Caldarelli, Guido",55872867700;56121765800;6603263932;24775109100;36781874700;6603265005;36344077800;36912065800;55139905100
10.1080/14697688.2021.1890807,2,"One of the most challenging aspects in the analysis and modelling of financial markets, including Credit Default Swap (CDS) markets, is the presence of an emergent, intermediate level of structure standing in between the microscopic dynamics of individual financial entities and the macroscopic dynamics of the market as a whole. This elusive, mesoscopic level of organisation is often sought for via factor models that ultimately decompose the market according to geographic regions and economic industries. However, at a more general level, the presence of mesoscopic structure might be revealed in an entirely data-driven approach, looking for a modular and possibly hierarchical organisation of the empirical correlation matrix between financial time series. The crucial ingredient in such an approach is the definition of an appropriate null model for the correlation matrix. Recent research showed that community detection techniques developed for networks become intrinsically biased when applied to correlation matrices. For this reason, a method based on Random Matrix Theory has been developed, which identifies the optimal hierarchical decomposition of the system into internally correlated and mutually anti-correlated communities. Building upon this technique, here we resolve the mesoscopic structure of the CDS market and identify groups of issuers that cannot be traced back to standard industry/region taxonomies, thereby being inaccessible to standard factor models. We use this decomposition to introduce a novel default risk model that is shown to outperform more traditional alternatives.","Anagnostou, I.;Squartini, T.;Kandhai, D.;Garlaschelli, D.",57200941877;36912065800;6603943677;6603265005
10.3389/fphy.2020.00286,23,"Cryptocurrencies are distributed systems that allow exchanges of native (and non-) tokens between participants. The availability of the complete historical bookkeeping opens up an unprecedented possibility: that of understanding the evolution of a cryptocurrency's network structure while gaining useful insights into the relationships between users' behavior and cryptocurrency pricing in exchange markets. In this article we review some recent results concerning the structural properties of the Bitcoin Transaction Networks, a generic name referring to a set of three different constructs: the Bitcoin Address Network, the Bitcoin User Network, and the Bitcoin Lightning Network. The picture that emerges is of a system growing over time, which becomes increasingly sparse and whose mesoscopic structural organization is characterized by the presence of an increasingly significant core-periphery structure. Such a peculiar topology is accompanied by a highly uneven distribution of bitcoins, a result suggesting that Bitcoin is becoming an increasingly centralized system at different levels.","Vallarano, Nicoló;Tessone, Claudio J.;Squartini, Tiziano",57219510828;6602779977;36912065800
10.1088/1367-2630/aba062,29,"The Bitcoin lightning network (BLN), a so-called 'second layer' payment protocol, was launched in 2018 to scale up the number of transactions between Bitcoin owners. In this paper, we analyse the structure of the BLN over a period of 18 months, ranging from 12th January 2018 to 17th July 2019, at the end of which the network has reached 8.216 users, 122.517 active channels and 2.732,5 transacted Bitcoins. Here, we consider three representations of the BLN: the daily snapshot one, the weekly snapshot one and the daily-block snapshot one. By studying the topological properties of the binary and weighted versions of the three representations above, we find that the total volume of transacted Bitcoins approximately grows as the square of the network size; however, despite the huge activity characterising the BLN, the Bitcoins distribution is very unequal: the average Gini coefficient of the node strengths (computed across the entire history of the Bitcoin lightning network) is, in fact, ≃0.88 causing the 10% (50%) of the nodes to hold the 80% (99%) of the Bitcoins at stake in the BLN (on average, across the entire period). This concentration brings up the question of which minimalist network model allows us to explain the network topological structure. Like for other economic systems, we hypothesise that local properties of nodes, like the degree, ultimately determine part of its characteristics. Therefore, we have tested the goodness of the undirected binary configuration model (UBCM) in reproducing the structural features of the BLN: the UBCM recovers the disassortative and the hierarchical character of the BLN but underestimates the centrality of nodes; this suggests that the BLN is becoming an increasingly centralised network, more and more compatible with a core-periphery structure. Further inspection of the resilience of the BLN shows that removing hubs leads to the collapse of the network into many components, an evidence suggesting that this network may be a target for the so-called split attacks.","Lin, Jian Hong;Primicerio, Kevin;Squartini, Tiziano;Decker, Christian;Tessone, Claudio J.",56996303000;57192640151;36912065800;57196776143;6602779977
10.1088/1367-2630/ab74a7,11,"Due to the interconnectedness of financial entities, estimating certain key properties of a complex financial system, including the implied level of systemic risk, requires detailed information about the structure of the underlying network of dependencies. However, since data about financial linkages are typically subject to confidentiality, network reconstruction techniques become necessary to infer both the presence of connections and their intensity. Recently, several 'horse races' have been conducted to compare the performance of the available financial network reconstruction methods. These comparisons were based on arbitrarily chosen metrics of similarity between the real network and its reconstructed versions. Here we establish a generalized maximum-likelihood approach to rigorously define and compare weighted reconstruction methods. Our generalization uses the maximization of a certain conditional entropy to solve the problem represented by the fact that the density-dependent constraints required to reliably reconstruct the network are typically unobserved and, therefore, cannot enter directly, as sufficient statistics, in the likelihood function. The resulting approach admits as input any reconstruction method for the purely binary topology and, conditionally on the latter, exploits the available partial information to infer link weights. We find that the most reliable method is obtained by 'dressing' the best-performing binary method with an exponential distribution of link weights having a properly density-corrected and link-specific mean value and propose two safe (i.e. unbiased in the sense of maximum conditional entropy) variants of it. While the one named CReMA is perfectly general (as a particular case, it can place optimal weights on a network if the bare topology is known), the one named CReMB is recommended both in case of full uncertainty about the network topology and if the existence of some links is certain. In these cases, the CReMB is faster and reproduces empirical networks with highest generalized likelihood among the considered competing models.","Parisi, Federica;Squartini, Tiziano;Garlaschelli, Diego",57208624523;36912065800;6603265005
10.1209/0295-5075/125/68001,15,"Detecting the presence of mesoscale structures in complex networks is of primary importance. This is especially true for financial networks, whose structural organization deeply affects their resilience to events like default cascades, shocks propagation, etc. Several methods have been proposed, so far, to detect communities, i.e., groups of nodes whose internal connectivity is significantly large. Communities, however do not represent the only kind of mesoscale structures characterizing real-world networks: Other examples are provided by bow-tie structures, core-periphery structures and bipartite structures. Here we propose a novel method to detect statistically significant bimodular structures, i.e., either bipartite or core-periphery ones. It is based on a modification of the surprise, recently proposed for detecting communities. Our variant allows for bimodular nodes partitions to be revealed, by letting links to be placed either 1) within the core part and between the core and the periphery parts or 2) between the layers of a bipartite network. From a technical point of view, this is achieved by employing a multinomial hypergeometric distribution instead of the traditional, binomial hypergeometric one; as in the latter case, this allows a p-value to be assigned to any given (bi)partition of the nodes. To illustrate the performance of our method, we report the results of its application to several real-world networks, including social, economic and financial ones.","Van Lidth De Jeude, J.;Caldarelli, G.;Squartini, T.",57205571469;55139905100;36912065800
10.1038/s42254-018-0002-6,197,"In the past 15 years, statistical physics has been successful as a framework for modelling complex networks. On the theoretical side, this approach has unveiled a variety of physical phenomena, such as the emergence of mixed distributions and ensemble non-equivalence, that are observed in heterogeneous networks but not in homogeneous systems. At the same time, thanks to the deep connection between the principle of maximum entropy and information theory, statistical physics has led to the definition of null models for networks that reproduce features of real-world systems but that are otherwise as random as possible. We review here the statistical physics approach and the null models for complex networks, focusing in particular on analytical frameworks that reproduce local network features. We show how these models have been used to detect statistically significant structural patterns in real-world networks and to reconstruct the network structure in cases of incomplete information. We further survey the statistical physics models that reproduce more complex, semilocal network features using Markov chain Monte Carlo sampling, as well as models of generalized network structures, such as multiplex networks, interacting networks and simplicial complexes.","Cimini, Giulio;Squartini, Tiziano;Saracco, Fabio;Garlaschelli, Diego;Gabrielli, Andrea;Caldarelli, Guido",36781874700;36912065800;36344077800;6603265005;57222737548;55139905100
10.1155/2019/5120581,22,"When facing the problem of reconstructing complex mesoscale network structures, it is generally believed that models encoding the nodes organization into modules must be employed. The present paper focuses on two block structures that characterize the empirical mesoscale organization of many real-world networks, i.e., the bow-tie and the core-periphery ones, with the aim of quantifying the minimal amount of topological information that needs to be enforced in order to reproduce the topological details of the former. Our analysis shows that constraining the network degree sequences is often enough to reproduce such structures, as confirmed by model selection criteria as AIC or BIC. As a byproduct, our paper enriches the toolbox for the analysis of bipartite networks, still far from being complete: both the bow-tie and the core-periphery structure, in fact, partition the networks into asymmetric blocks characterized by binary, directed connections, thus calling for the extension of a recently proposed method to randomize undirected, bipartite networks to the directed case.","Van Lidth De Jeude, Jeroen;Di Clemente, Riccardo;Caldarelli, Guido;Saracco, Fabio;Squartini, Tiziano",57205571469;55325867200;55139905100;36344077800;36912065800
10.1007/s41109-018-0073-4,14,"Link-prediction is an active research field within network theory, aiming at uncovering missing connections or predicting the emergence of future relationships from the observed network structure. This paper represents our contribution to the stream of research concerning missing links prediction. Here, we propose an entropy-based method to predict a given percentage of missing links, by identifying them with the most probable non-observed ones. The probability coefficients are computed by solving opportunely defined null-models over the accessible network structure. Upon comparing our likelihood-based, local method with the most popular algorithms over a set of economic, financial and food networks, we find ours to perform best, as pointed out by a number of statistical indicators (e.g. the precision, the area under the ROC curve, etc.). Moreover, the entropy-based formalism adopted in the present paper allows us to straightforwardly extend the link-prediction exercise to directed networks as well, thus overcoming one of the main limitations of current algorithms. The higher accuracy achievable by employing these methods - together with their larger flexibility - makes them strong competitors of available link-prediction algorithms.","Parisi, Federica;Caldarelli, Guido;Squartini, Tiziano",57208624523;55139905100;36912065800
10.1007/s10955-018-2076-z,4,"Information is a valuable asset in socio-economic systems, a significant part of which is entailed into the network of connections between agents. The different interlinkages patterns that agents establish may, in fact, lead to asymmetries in the knowledge of the network structure; since this entails a different ability of quantifying relevant, systemic properties (e.g. the risk of contagion in a network of liabilities), agents capable of providing a better estimation of (otherwise) inaccessible network properties, ultimately have a competitive advantage. In this paper, we address the issue of quantifying the information asymmetry of nodes: to this aim, we define a novel index—InfoRank—intended to rank nodes according to their information content. In order to do so, each node ego-network is enforced as a constraint of an entropy-maximization problem and the subsequent uncertainty reduction is used to quantify the node-specific accessible information. We, then, test the performance of our ranking procedure in terms of reconstruction accuracy and show that it outperforms other centrality measures in identifying the “most informative” nodes. Finally, we discuss the socio-economic implications of network information asymmetry.","Barucca, Paolo;Caldarelli, Guido;Squartini, Tiziano",56121765800;55139905100;36912065800
10.1007/s10955-018-2039-4,9,"Bipartite networks provide an insightful representation of many systems, ranging from mutualistic networks of species interactions to investment networks in finance. The analyses of their topological structures have revealed the ubiquitous presence of properties which seem to characterize many—apparently different—systems. Nestedness, for example, has been observed in biological plant-pollinator as well as in country-product exportation networks. Due to the interdisciplinary character of complex networks, tools developed in one field, for example ecology, can greatly enrich other areas of research, such as economy and finance, and vice versa. With this in mind, we briefly review several entropy-based bipartite null models that have been recently proposed and discuss their application to real-world systems. The focus on these models is motivated by the fact that they show three very desirable features: analytical character, general applicability, and versatility. In this respect, entropy-based methods have been proven to perform satisfactorily both in providing benchmarks for testing evidence-based null hypotheses and in reconstructing unknown network configurations from partial information. Furthermore, entropy-based models have been successfully employed to analyze ecological as well as economic systems. As an example, the application of entropy-based null models has detected early-warning signals, both in economic and financial systems, of the 2007–2008 world crisis. Moreover, they have revealed a statistically-significant export specialization phenomenon of country export baskets in international trade, a result that seems to reconcile Ricardo’s hypothesis in classical economics with recent findings on the (empirical) diversification industrial production at the national level. Finally, these null models have shown that the information contained in the nestedness is already accounted for by the degree sequence of the corresponding graphs.","Straka, Mika J.;Caldarelli, Guido;Squartini, Tiziano;Saracco, Fabio",57014786300;55139905100;36912065800;36344077800
10.1016/j.physrep.2018.06.008,57,"The study of social, economic and biological systems is often (when not always) limited by the partial information about the structure of the underlying networks. An example of paramount importance is provided by financial systems: information on the interconnections between financial institutions is privacy-protected, dramatically reducing the possibility of correctly estimating crucial systemic properties such as the resilience to the propagation of shocks. The need to compensate for the scarcity of data, while optimally employing the available information, has led to the birth of a research field known as network reconstruction. Since the latter has benefited from the contribution of researchers working in disciplines as different as mathematics, physics and economics, the results achieved so far are still scattered across heterogeneous publications. Most importantly, a systematic comparison of the network reconstruction methods proposed up to now is currently missing. This review aims at providing a unifying framework to present all these studies, mainly focusing on their application to economic and financial networks.","Squartini, Tiziano;Caldarelli, Guido;Cimini, Giulio;Gabrielli, Andrea;Garlaschelli, Diego",36912065800;55139905100;36781874700;57222737548;6603265005
10.3390/e20100743,8,"In this paper, we analyse the bipartite Colombian firms-products network, throughout a period of five years, from 2010 to 2014. Our analysis depicts a strongly modular system, with several groups of firms specializing in the export of specific categories of products. These clusters have been detected by running the bipartite variant of the traditional modularity maximization, revealing a bi-modular structure. Interestingly, this finding is refined by applying a recently proposed algorithm for projecting bipartite networks on the layer of interest and, then, running the Louvain algorithm on the resulting monopartite representations. Important structural differences emerge upon comparing the Colombian firms-products network with the World Trade Web, in particular, the bipartite representation of the latter is not characterized by a similar block-structure, as the modularity maximization fails in revealing (bipartite) nodes clusters. This points out that economic systems behave differently at different scales: while countries tend to diversify their production-potentially exporting a large number of different products-firms specialize in exporting (substantially very limited) baskets of basically homogeneous products.","Bruno, Matteo;Saracco, Fabio;Squartini, Tiziano;Dueñas, Marco",57204464985;36344077800;36912065800;55560192900
10.1103/PhysRevE.97.059904,0,Equations (4) and (5) in the paper contain typographical errors and should read(Formula Parsented).These typographical errors have no effect on the rest of the paper.,"Cimini, Giulio;Squartini, Tiziano;Gabrielli, Andrea;Garlaschelli, Diego",36781874700;36912065800;7102092279;6603265005
10.1155/2018/3132940,6,,"Squartini, Tiziano;Gabrielli, Andrea;Garlaschelli, Diego;Gili, Tommaso;Bifone, Angelo;Caccioli, Fabio",36912065800;57222737548;6603265005;13310221100;7004669829;24775109100
10.1007/s41109-017-0021-8,13,"Reconstructing weighted networks from partial information is necessary in many important circumstances, e.g. for a correct estimation of systemic risk. It has been shown that, in order to achieve an accurate reconstruction, it is crucial to reliably replicate the empirical degree sequence, which is however unknown in many realistic situations. More recently, it has been found that the knowledge of the degree sequence can be replaced by the knowledge of the strength sequence, which is typically accessible, complemented by that of the total number of links, thus considerably relaxing the observational requirements. Here we further relax these requirements and devise a procedure valid when even the the total number of links is unavailable. We assume that, apart from the heterogeneity induced by the degree sequence itself, the network is homogeneous, so that its (global) link density can be estimated by sampling subsets of nodes with representative density. We show that the best way of sampling nodes is the random selection scheme, any other procedure being biased towards unrealistically large, or small, link densities. We then introduce our core technique for reconstructing both the topology and the link weights of the unknown network in detail. When tested on real economic and financial data sets, our method achieves a remarkable accuracy and is very robust with respect to the sampled subsets, thus representing a reliable practical tool whenever the available topological information is restricted to small portions of nodes.","Squartini, Tiziano;Cimini, Giulio;Gabrielli, Andrea;Garlaschelli, Diego",36912065800;36781874700;57222737548;6603265005
10.1103/PhysRevE.96.032315,24,"Reconstructing patterns of interconnections from partial information is one of the most important issues in the statistical physics of complex networks. A paramount example is provided by financial networks. In fact, the spreading and amplification of financial distress in capital markets are strongly affected by the interconnections among financial institutions. Yet, while the aggregate balance sheets of institutions are publicly disclosed, information on single positions is mostly confidential and, as such, unavailable. Standard approaches to reconstruct the network of financial interconnection produce unrealistically dense topologies, leading to a biased estimation of systemic risk. Moreover, reconstruction techniques are generally designed for monopartite networks of bilateral exposures between financial institutions, thus failing in reproducing bipartite networks of security holdings (e.g., investment portfolios). Here we propose a reconstruction method based on constrained entropy maximization, tailored for bipartite financial networks. Such a procedure enhances the traditional capital-asset pricing model (CAPM) and allows us to reproduce the correct topology of the network. We test this enhanced CAPM (ECAPM) method on a dataset, collected by the European Central Bank, of detailed security holdings of European institutional sectors over a period of six years (2009-2015). Our approach outperforms the traditional CAPM and the recently proposed maximum-entropy CAPM both in reproducing the network topology and in estimating systemic risk due to fire sales spillovers. In general, ECAPM can be applied to the whole class of weighted bipartite networks described by the fitness model.","Squartini, Tiziano;Almog, Assaf;Caldarelli, Guido;Van Lelyveld, Iman;Garlaschelli, Diego;Cimini, Giulio",36912065800;14832317300;55139905100;6506071581;6603265005;36781874700
10.1088/1367-2630/aa6b38,74,"Bipartite networks are currently regarded as providing a major insight into the organization of many real-world systems, unveiling the mechanisms driving the interactions occurring between distinct groups of nodes. One of the most important issues encountered when modeling bipartite networks is devising a way to obtain a (monopartite) projection on the layer of interest, which preserves as much as possible the information encoded into the original bipartite structure. In the present paper we propose an algorithm to obtain statistically-validated projections of bipartite networks, according to which any two nodes sharing a statistically-significant number of neighbors are linked. Since assessing the statistical significance of nodes similarity requires a proper statistical benchmark, here we consider a set of four null models, defined within the exponential random graph framework. Our algorithm outputs a matrix of link-specific p-values, from which a validated projection is straightforwardly obtainable, upon running a multiple hypothesis testing procedure. Finally, we test our method on an economic network (i.e. the countries-products World Trade Web representation) and a social network (i.e. MovieLens, collecting the users' ratings of a list of movies). In both cases non-trivial communities are detected: while projecting the World Trade Web on the countries layer reveals modules of similarly-industrialized nations, projecting it on the products layer allows communities characterized by an increasing level of complexity to be detected; in the second case, projecting MovieLens on the films layer allows clusters of movies whose affinity cannot be fully accounted for by genre similarity to be individuated.","Saracco, Fabio;Straka, Mika J.;Di Clemente, Riccardo;Gabrielli, Andrea;Caldarelli, Guido;Squartini, Tiziano",36344077800;57014786300;55325867200;57222737548;55139905100;36912065800
10.1504/IJCEE.2017.086875,9,"The International Trade Network (ITN) is the network formed by trade relationships between world countries. The complex structure of the ITN impacts important economic processes such as globalisation, competitiveness, and the propagation of instabilities. Modelling the structure of the ITN in terms of simple macroeconomic quantities is therefore of paramount importance. While traditional macroeconomics has mainly used the gravity model to characterise the magnitude of trade volumes, modern network theory has predominantly focused on modelling the topology of the ITN. Combining these two complementary approaches is still an open problem. Here we review these approaches and emphasise the double role played by gross domestic product (GDP) in empirically determining both the existence and the volume of trade linkages. Moreover, we discuss a unified model that exploits these patterns and uses only the GDP as the relevant macroeconomic factor for reproducing both the topology and the link weights of the ITN.","Almog, Assaf;Squartini, Tiziano;Garlaschelli, Diego",14832317300;36912065800;6603265005
,0,,"Bordino, Ilaria;Caldarelli, Guido;Fumarola, Fabio;Gullo, Francesco;Squartini, Tiziano",26325355900;55139905100;26325359300;22034355400;36912065800
10.1103/PhysRevE.94.042316,15,"Real-world multilayer networks feature nontrivial dependencies among links of different layers. Here we argue that if links are directed, then dependencies are twofold. Besides the ordinary tendency of links of different layers to align as the result of ""multiplexity,"" there is also a tendency to antialign as a result of what we call ""multireciprocity,"" i.e., the fact that links in one layer can be reciprocated by opposite links in a different layer. Multireciprocity generalizes the scalar definition of single-layer reciprocity to that of a square matrix involving all pairs of layers. We introduce multiplexity and multireciprocity matrices for both binary and weighted multiplexes and validate their statistical significance against maximum-entropy null models that filter out the effects of node heterogeneity. We then perform a detailed empirical analysis of the world trade multiplex (WTM), representing the import-export relationships between world countries in different commodities. We show that the WTM exhibits strong multiplexity and multireciprocity, an effect which is, however, largely encoded into the degree or strength sequences of individual layers. The residual effects are still significant and allow us to classify pairs of commodities according to their tendency to be traded together in the same direction and/or in opposite ones. We also find that the multireciprocity of the WTM is significantly lower than the usual reciprocity measured on the aggregate network. Moreover, layers with low (high) internal reciprocity are embedded within sets of layers with comparably low (high) mutual multireciprocity. This suggests that, in the WTM, reciprocity is inherent to groups of related commodities rather than to individual commodities. We discuss the implications for international trade research focusing on product taxonomies, the product space, and fitness and complexity metrics.","Gemmetto, Valerio;Squartini, Tiziano;Picciolo, Francesco;Ruzzenenti, Franco;Garlaschelli, Diego",56534251200;36912065800;53881839300;24473499100;6603265005
10.1140/epjst/e2016-60019-3,3,"In recent years, in Italy, the trend of the electricity demand and the need to connect a large number of renewable energy power generators to the power-grid, developed a novel type of energy transmission/distribution infrastructure. The Italian Transmission System Operator (TSO) and the Distribution System Operator (DSO), worked on a new infrastructural model, based on electronic meters and information technology. In pursuing this objective it is crucial importance to understand how even more larger shares of renewable energy can be fully integrated, providing a constant and reliable energy background over space and time. This is particularly true for intermittent sources as photovoltaic installations due to the fine-grained distribution of them across the Country. In this work we use an over-simplified model to characterize the Italian power grid as a graph whose nodes are Italian municipalities and the edges cross the administrative boundaries between a selected municipality and its first neighbours, following a Delaunay triangulation. Our aim is to describe the power flow as a diffusion process over a network, and using open data on the solar irradiation at the ground level, we estimate the production of photovoltaic energy in each node. An attraction index was also defined using demographic data, in accordance with average per capita energy consumption data. The available energy on each node was calculated by finding the stationary state of a generation-attraction model.","Valori, Luca;Giannuzzi, Giovanni Luca;Facchini, Angelo;Squartini, Tiziano;Garlaschelli, Diego;Basosi, Riccardo",54935758100;56074172600;7102434045;36912065800;6603265005;7003824787
10.1038/srep32060,23,"This paper represents a contribution to the study of the brain functional connectivity from the perspective of complex networks theory. More specifically, we apply graph theoretical analyses to provide evidence of the modular structure of the mouse brain and to shed light on its hierarchical organization. We propose a novel percolation analysis and we apply our approach to the analysis of a resting-state functional MRI data set from 41 mice. This approach reveals a robust hierarchical structure of modules persistent across different subjects. Importantly, we test this approach against a statistical benchmark (or null model) which constrains only the distributions of empirical correlations. Our results unambiguously show that the hierarchical character of the mouse brain modular structure is not trivially encoded into this lower-order constraint. Finally, we investigate the modular structure of the mouse brain by computing the Minimal Spanning Forest, a technique that identifies subnetworks characterized by the strongest internal correlations. This approach represents a faster alternative to other community detection methods and provides a means to rank modules on the basis of the strength of their internal edges.","Bardella, Giampiero;Bifone, Angelo;Gabrielli, Andrea;Gozzi, Alessandro;Squartini, Tiziano",57190808174;7004669829;57222737548;6602786023;36912065800
10.1038/srep30286,83,"Since 2007, several contributions have tried to identify early-warning signals of the financial crisis. However, the vast majority of analyses has focused on financial systems and little theoretical work has been done on the economic counterpart. In the present paper we fill this gap and employ the theoretical tools of network theory to shed light on the response of world trade to the financial crisis of 2007 and the economic recession of 2008-2009. We have explored the evolution of the bipartite World Trade Web (WTW) across the years 1995-2010, monitoring the behavior of the system both before and after 2007. Our analysis shows early structural changes in the WTW topology: since 2003, the WTW becomes increasingly compatible with the picture of a network where correlations between countries and products are progressively lost. Moreover, the WTW structural modification can be considered as concluded in 2010, after a seemingly stationary phase of three years. We have also refined our analysis by considering specific subsets of countries and products: the most statistically significant early-warning signals are provided by the most volatile macrosectors, especially when measured on developing countries, suggesting the emerging economies as being the most sensitive ones to the global economic cycles.","Saracco, Fabio;Di Clemente, Riccardo;Gabrielli, Andrea;Squartini, Tiziano",36344077800;55325867200;57222737548;36912065800
,0,,"Bordino, Ilaria;Caldarelli, Guido;Fumarola, Fabio;Gullo, Francesco;Squartini, Tiziano",26325355900;55139905100;26325359300;22034355400;36912065800
10.1103/PhysRevLett.115.268701,45,"It is generally believed that, in the thermodynamic limit, the microcanonical description as a function of energy coincides with the canonical description as a function of temperature. However, various examples of systems for which the microcanonical and canonical ensembles are not equivalent have been identified. A complete theory of this intriguing phenomenon is still missing. Here we show that ensemble nonequivalence can manifest itself also in random graphs with topological constraints. We find that, while graphs with a given number of links are ensemble equivalent, graphs with a given degree sequence are not. This result holds irrespective of whether the energy is nonadditive (as in unipartite graphs) or additive (as in bipartite graphs). In contrast with previous expectations, our results show that (1) physically, nonequivalence can be induced by an extensive number of local constraints, and not necessarily by long-range interactions or nonadditivity, (2) mathematically, nonequivalence is determined by a different large-deviation behavior of microcanonical and canonical probabilities for a single microstate, and not necessarily for almost all microstates. The latter criterion, which is entirely local, is not restricted to networks and holds in general.","Squartini, Tiziano;De Mol, Joey;Den Hollander, Frank;Garlaschelli, Diego",36912065800;57038631800;7003630220;6603265005
10.1038/srep15758,88,"We address a fundamental problem that is systematically encountered when modeling real-world complex systems of societal relevance: the limitedness of the information available. In the case of economic and financial networks, privacy issues severely limit the information that can be accessed and, as a consequence, the possibility of correctly estimating the resilience of these systems to events such as financial shocks, crises and cascade failures. Here we present an innovative method to reconstruct the structure of such partially-accessible systems, based on the knowledge of intrinsic node-specific properties and of the number of connections of only a limited subset of nodes. This information is used to calibrate an inference procedure based on fundamental concepts derived from statistical physics, which allows to generate ensembles of directed weighted networks intended to represent the real system-so that the real network properties can be estimated as their average values within the ensemble. We test the method both on synthetic and empirical networks, focusing on the properties that are commonly used to measure systemic risk. Indeed, the method shows a remarkable robustness with respect to the limitedness of the information available, thus representing a valuable tool for gaining insights on privacy-protected economic and financial systems.","Cimini, Giulio;Squartini, Tiziano;Garlaschelli, Diego;Gabrielli, Andrea",36781874700;36912065800;6603265005;57222737548
10.1088/1742-5468/2015/10/P10002,34,"The q-voter model, a variant of the classic voter model, has been analyzed by several authors. While allowing us to study opinion dynamics, this model is also believed to be one of the most representative among the many defined in the wide field of sociophysics. Here, we investigate the consequences of conformity on the consensus reaching process, by numerically simulating a q-voter model with agents behaving either as conformists or nonconformists, embedded on heterogeneous network topologies (as small-world and scale-free). In fact, although it is already known that conformity enhances the reaching of consensus, the related process is often studied only on fully-connected networks, thus strongly limiting our full understanding of it. This paper represents a first step in the direction of analyzing more realistic social models, showing that different opinion formation phases, driven by the conformist agents density, are observable. As a result, we identify threshold values of the density of conformist agents, varying across different topologies and separating different regimes of our system, ranging from a disordered phase, where different opinions coexist, to a gradually more ordered phase, where consensus is eventually reached.","Alberto Javarone, Marco;Squartini, Tiziano",55601598500;36912065800
10.1103/PhysRevE.92.040802,37,"A problem typically encountered when studying complex systems is the limitedness of the information available on their topology, which hinders our understanding of their structure and of the dynamical processes taking place on them. A paramount example is provided by financial networks, whose data are privacy protected: Banks publicly disclose only their aggregate exposure towards other banks, keeping individual exposures towards each single bank secret. Yet, the estimation of systemic risk strongly depends on the detailed structure of the interbank network. The resulting challenge is that of using aggregate information to statistically reconstruct a network and correctly predict its higher-order properties. Standard approaches either generate unrealistically dense networks, or fail to reproduce the observed topology by assigning homogeneous link weights. Here, we develop a reconstruction method, based on statistical mechanics concepts, that makes use of the empirical link density in a highly nontrivial way. Technically, our approach consists in the preliminary estimation of node degrees from empirical node strengths and link density, followed by a maximum-entropy inference based on a combination of empirical strengths and estimated degrees. Our method is successfully tested on the international trade network and the interbank money market, and represents a valuable tool for gaining insights on privacy-protected or partially accessible systems.","Cimini, Giulio;Squartini, Tiziano;Gabrielli, Andrea;Garlaschelli, Diego",36781874700;36912065800;57222737548;6603265005
10.1038/srep10595,103,"Within the last fifteen years, network theory has been successfully applied both to natural sciences and to socioeconomic disciplines. In particular, bipartite networks have been recognized to provide a particularly insightful representation of many systems, ranging from mutualistic networks in ecology to trade networks in economy, whence the need of a pattern detection-oriented analysis in order to identify statistically-significant structural properties. Such an analysis rests upon the definition of suitable null models, i.e. upon the choice of the portion of network structure to be preserved while randomizing everything else. However, quite surprisingly, little work has been done so far to define null models for real bipartite networks. The aim of the present work is to fill this gap, extending a recently-proposed method to randomize monopartite networks to bipartite networks. While the proposed formalism is perfectly general, we apply our method to the binary, undirected, bipartite representation of the World Trade Web, comparing the observed values of a number of structural quantities of interest with the expected ones, calculated via our randomization procedure. Interestingly, the behavior of the World Trade Web in this new representation is strongly different from the monopartite analogue, showing highly non-trivial patterns of self-organization.","Saracco, Fabio;Di Clemente, Riccardo;Gabrielli, Andrea;Squartini, Tiziano",36344077800;55325867200;57222737548;36912065800
10.1371/journal.pone.0125077,5,"In the context of agent based modeling and network theory, we focus on the problem of recovering behavior-related choice information from origin-destination type data, a topic also known under the name of network tomography. As a basis for predicting agents' choices we emphasize the connection between adaptive intelligent behavior, causal entropy maximization, and self-organized behavior in an open dynamic system. We cast this problem in the form of binary and weighted networks and suggest information theoretic entropy-driven methods to recover estimates of the unknown behavioral flow parameters. Our objective is to recover the unknown behavioral values across the ensemble analytically, without explicitly sampling the configuration space. In order to do so, we consider the Cressie-Read family of entropic functionals, enlarging the set of estimators commonly employed to make optimal use of the available information. More specifically, we explicitly work out two cases of particular interest: Shannon functional and the likelihood functional. We then employ them for the analysis of both univariate and bivariate data sets, comparing their accuracy in reproducing the observed trends.","Squartini, Tiziano;Ser-Giacomi, Enrico;Garlaschelli, Diego;Judge, George",36912065800;55199831700;6603265005;6701716155
10.1093/comnet/cnu012,10,"Economic integration, globalization and financial crises represent examples of processes whose understanding requires the analysis of the underlying network structure. Of particular interest is establishing whether a real economic network is in a state of (quasi)stationary equilibrium, i.e. characterized by smooth structural changes rather than abrupt transitions. While in the former case the behaviour of the system can be reasonably controlled and predicted, in the latter case this is generally impossible. Here, we propose a method to assess whether a real economic network is in a quasi-stationary state by checking the consistency of its structural evolution with appropriate quasi-equilibrium maximum-entropy ensembles of graphs. As illustrative examples, we consider the International Trade Network (ITN) and the Dutch Interbank Network (DIN). We find that the ITN is an almost perfect example of quasi-equilibrium network, while the DIN is clearly out-of-equilibrium. In the latter, the entity of the deviation from quasistationarity contains precious information that allows us to identify remarkable early warning signals of the interbank crisis of 2008. These early warning signals involve certain dyadic and triadic topological properties, including dangerous 'debt loops' with different levels of interbank reciprocity.","Squartini, Tiziano;Garlaschelli, Diego",36912065800;6603265005
10.1088/1367-2630/17/2/023052,59,"Sampling random graphs with given properties is a key step in the analysis of networks, as random ensembles represent basic null models required to identify patterns such as communities and motifs. An important requirement is that the sampling process is unbiased and efficient. The main approaches are microcanonical, i.e. they sample graphs that match the enforced constraints exactly. Unfortunately, when applied to strongly heterogeneous networks (like most real-world examples), the majority of these approaches become biased and/or time-consuming. Moreover, the algorithms defined in the simplest cases, such as binary graphs with given degrees, are not easily generalizable to more complicated ensembles. Here we propose a solution to the problem via the introduction of a 'Maximize and Sample' ('Max & Sam' for short) method to correctly sample ensembles of networks where the constraints are 'soft', i.e. realized as ensemble averages. Our method is based on exact maximum-entropy distributions and is therefore unbiased by construction, even for strongly heterogeneous networks. It is also more computationally efficient than most microcanonical alternatives. Finally, it works for both binary and weighted networks with a variety of constraints, including combined degree-strength sequences and full reciprocity structure, for which no alternative method exists. Our canonical approach can in principle be turned into an unbiased microcanonical one, via a restriction to the relevant subset. Importantly, the analysis of the fluctuations of the constraints suggests that the microcanonical and canonical versions of all the ensembles considered here are not equivalent. We show various real-world applications and provide a code implementing all our algorithms.","Squartini, Tiziano;Mastrandrea, Rossana;Garlaschelli, Diego",36912065800;56150284600;6603265005
10.1088/1367-2630/17/1/013009,27,"Recent events such as the global financial crisis have renewed the interest in the topic of economic networks. One of the main channels of shock propagation among countries is the International Trade Network (ITN). Two important models for the ITN structure, the classical gravity model of trade (more popular among economists) and the fitness model (more popular among networks scientists), are both limited to the characterization of only one representation of the ITN. The gravity model satisfactorily predicts the volume of trade between connected countries, but cannot reproduce the missing links (i.e. the topology). On the other hand, the fitness model can successfully replicate the topology of the ITN, but cannot predict the volumes. This paper tries to make an important step forward in the unification of those two frameworks, by proposing a new gross domestic product (GDP) driven model which can simultaneously reproduce the binary and the weighted properties of the ITN. Specifically, we adopt a maximum-entropy approach where both the degree and the strength of each node are preserved. We then identify strong nonlinear relationships between the GDP and the parameters of the model. This ultimately results in a weighted generalization of the fitness model of trade, where the GDP plays the role of a 'macroeconomic fitness' shaping the binary and the weighted structure of the ITN simultaneously. Our model mathematically explains an important asymmetry in the role of binary and weighted network properties, namely the fact that binary properties can be inferred without the knowledge of weighted ones, while the opposite is not true.","Almog, Assaf;Squartini, Tiziano;Garlaschelli, Diego",14832317300;36912065800;6603265005
10.1007/978-3-319-15168-7_40,0,"Recent years have witnessed the increasing interest of physicists, mathematicians and computer scientists for socio-economic systems. In our view, the many reasons behind this can be summarized by observing that traditional approaches to disciplines as sociology and economics have dramatically shown their limitations.","Galam, Serge;Javarone, Marco Alberto;Squartini, Tiziano",7004128178;55601598500;36912065800
10.1007/978-3-319-15168-7_41,5,"A major problem in the study of complex socioeconomic systems is represented by privacy issues—that can put severe limitations on the amount of accessible information, forcing to build models on the basis of incomplete knowledge. In this paper we investigate a novel method to reconstruct global topological properties of a complex network starting from limited information. This method uses the knowledge of an intrinsic property of the nodes (indicated as fitness), and the number of connections of only a limited subset of nodes, in order to generate an ensemble of exponential random graphs that are representative of the real systems and that can be used to estimate its topological properties. Here we focus in particular on reconstructing the most basic properties that are commonly used to describe a network: density of links, assortativity, clustering. We test the method on both benchmark synthetic networks and real economic and financial systems, finding a remarkable robustness with respect to the number of nodes used for calibration. The method thus represents a valuable tool for gaining insights on privacy-protected systems.","Cimini, Giulio;Squartini, Tiziano;Musmeci, Nicolò;Puliga, Michelangelo;Gabrielli, Andrea;Garlaschelli, Diego;Battiston, Stefano;Caldarelli, Guido",36781874700;36912065800;55606793300;15077156900;57222737548;6603265005;6603263932;55139905100
10.1103/PhysRevE.90.062804,39,"In economic and financial networks, the strength of each node has always an important economic meaning, such as the size of supply and demand, import and export, or financial exposure. Constructing null models of networks matching the observed strengths of all nodes is crucial in order to either detect interesting deviations of an empirical network from economically meaningful benchmarks or reconstruct the most likely structure of an economic network when the latter is unknown. However, several studies have proved that real economic networks and multiplexes topologically differ from configurations inferred only from node strengths. Here we provide a detailed analysis of the world trade multiplex by comparing it to an enhanced null model that simultaneously reproduces the strength and the degree of each node. We study several temporal snapshots and almost 100 layers (commodity classes) of the multiplex and find that the observed properties are systematically well reproduced by our model. Our formalism allows us to introduce the (static) concept of extensive and intensive bias, defined as a measurable tendency of the network to prefer either the formation of extra links or the reinforcement of link weights, with respect to a reference case where only strengths are enforced. Our findings complement the existing economic literature on (dynamic) intensive and extensive trade margins. More generally, they show that real-world multiplexes can be strongly shaped by layer-specific local constraints.","Mastrandrea, Rossana;Squartini, Tiziano;Fagiolo, Giorgio;Garlaschelli, Diego",56150284600;36912065800;6507866198;6603265005
10.1088/1367-2630/16/4/043022,78,"Network topology plays a key role in many phenomena, from the spreading of diseases to that of financial crises. Whenever the whole structure of a network is unknown, one must resort to reconstruction methods that identify the least biased ensemble of networks consistent with the partial information available. A challenging case, frequently encountered due to privacy issues in the analysis of interbank flows and Big Data, is when there is only local (node-specific) aggregate information available. For binary networks, the relevant ensemble is one where the degree (number of links) of each node is constrained to its observed value. However, for weighted networks the problem is much more complicated. While the näve approach prescribes to constrain the strengths (total link weights) of all nodes, recent counter-intuitive results suggest that in weighted networks the degrees are often more informative than the strengths. This implies that the reconstruction of weighted networks would be significantly enhanced by the specification of both strengths and degrees, a computationally hard and bias-prone procedure. Here we solve this problem by introducing an analytical and unbiased maximum-entropy method that works in the shortest possible time and does not require the explicit generation of reconstructed samples. We consider several real-world examples and show that, while the strengths alone give poor results, the additional knowledge of the degrees yields accurately reconstructed networks. Information-theoretic criteria rigorously confirm that the degree sequence, as soon as it is non-trivial, is irreducible to the strength sequence. Our results have strong implications for the analysis of motifs and communities and whenever the reconstructed ensemble is required as a null model to detect higher-order patterns. © 2014 IOP Publishing Ltd and Deutsche Physikalische Gesellschaft.","Mastrandrea, Rossana;Squartini, Tiziano;Fagiolo, Giorgio;Garlaschelli, Diego",56150284600;36912065800;6507866198;6603265005
10.1109/SITIS.2013.89,2,"Economic and financial networks play a crucial role in various important processes, including economic integration, globalization, and financial crises. Of particular interest is understanding whether the temporal evolution of a real economic network is in a (quasi-)stationary equilibrium, i.e. characterized by smooth structural changes rather than abrupt transitions. Smooth changes in quasi-equilibrium networks can be generally controlled for, and largely predicted, while this is generally not possible for abrupt transitions in non-stationary networks. Here we study whether real economic networks are in or out of equilibrium by checking their consistency with quasi-equilibrium maximum-entropy ensembles of graphs. As illustrative examples, we consider the International Trade Network (ITN) and the Dutch Interbank Network (DIN). We show that, despite the globalization process, the ITN is an almost perfect example of quasi-equilibrium network, while the DIN is clearly an out-of-equilibrium network undergoing major structural changes and displaying non-stationary dynamics. Among the out-of-equilibrium properties of the DIN, we find striking early-warning signals of the interbank crisis of 2008. © 2013 IEEE.","Squartini, Tiziano;Garlaschelli, Diego",36912065800;6603265005
10.1038/srep03357,104,"The financial crisis clearly illustrated the importance of characterizing the level of 'systemic' risk associated with an entire credit network, rather than with single institutions. However, the interplay between financial distress and topological changes is still poorly understood. Here we analyze the quarterly interbank exposures among Dutch banks over the period 1998-2008, ending with the crisis. After controlling for the link density, many topological properties display an abrupt change in 2008, providing a clear - but unpredictable - signature of the crisis. By contrast, if the heterogeneity of banks' connectivity is controlled for, the same properties show a gradual transition to the crisis, starting in 2005 and preceded by an even earlier period during which anomalous debt loops could have led to the underestimation of counter-party risk. These early-warning signals are undetectable if the network is reconstructed from partial bank-specific data, as routinely done. We discuss important implications for bank regulatory policies.","Squartini, Tiziano;Van Lelyveld, Iman;Garlaschelli, Diego",36912065800;6506071581;6603265005
10.1038/srep02729,96,"In directed networks, reciprocal links have dramatic effects on dynamical processes, network growth, and higher-order structures such as motifs and communities. While the reciprocity of binary networks has been extensively studied, that of weighted networks is still poorly understood, implying an ever-increasing gap between the availability of weighted network data and our understanding of their dyadic properties. Here we introduce a general approach to the reciprocity of weighted networks, and define quantities and null models that consistently capture empirical reciprocity patterns at different structural levels. We show that, counter-intuitively, previous reciprocity measures based on the similarity of mutual weights are uninformative. By contrast, our measures allow to consistently classify different weighted networks according to their reciprocity, track the evolution of a network's reciprocity over time, identify patterns at the level of dyads and vertices, and distinguish the effects of flux (im)balances or other (a)symmetries from a true tendency towards (anti-)reciprocation.","Squartini, Tiziano;Picciolo, Francesco;Ruzzenenti, Franco;Garlaschelli, Diego",36912065800;53881839300;24473499100;6603265005
10.1007/s11403-012-0104-7,60,"In all empirical-network studies, the observed properties of economic networks are informative only if compared with a well-defined null model that can quantitatively predict the behavior of such properties in constrained graphs. However, predictions of the available null-model methods can be derived analytically only under assumptions (e. g., sparseness of the network) that are unrealistic for most economic networks like the world trade web (WTW). In this paper we study the evolution of the WTW using a recently-proposed family of null network models. The method allows to analytically obtain the expected value of any network statistic across the ensemble of networks that preserve on average some local properties, and are otherwise fully random. We compare expected and observed properties of the WTW in the period 1950-2000, when either the expected number of trade partners or total country trade is kept fixed and equal to observed quantities. We show that, in the binary WTW, node-degree sequences are sufficient to explain higher-order network properties such as disassortativity and clustering-degree correlation, especially in the last part of the sample. Conversely, in the weighted WTW, the observed sequence of total country imports and exports are not sufficient to predict higher-order patterns of the WTW. We discuss some important implications of these findings for international-trade models. © 2012 Springer-Verlag.","Fagiolo, Giorgio;Squartini, Tiziano;Garlaschelli, Diego",6507866198;36912065800;6603265005
10.1007/978-3-642-28583-7_3,34,"In self-organizing networks, topology and dynamics coevolve in a continuous feedback, without exogenous driving. The World Trade Network (WTN) is one of the few empirically well documented examples of self-organizing networks: its topology depends on the GDP of world countries, which in turn depends on the structure of trade. Therefore, understanding the WTN topological properties deviating from randomness provides direct empirical information about the structural effects of self-organization. Here, using an analytical pattern-detection method we have recently proposed, we study the occurrence of triadic ‘motifs’ (three-vertices subgraphs) in the WTN between 1950 and 2000. We find that motifs are not explained by only the in- and out-degree sequences, but they are completely explained if also the numbers of reciprocal edges are taken into account. This implies that the self-organization process underlying the evolution of the WTN is almost completely encoded into the dyadic structure, which strongly depends on reciprocity.","Squartini, Tiziano;Garlaschelli, Diego",36912065800;6603265005
,0,"One problem in the study of the Italian electric energy supply scenario is determining the ability of photovoltaic production to provide a constant and stable energy background over space and time. Knowing how the photovoltaic energy produced in a given node diffuses on the power grid is of crucial importance. A smart grid able to face peaks of load must be designed. Approached here from a complex systems point of view, the network of energy supply might be represented by a graph in which nodes are Italian municipalities and edges cross the administrative boundaries from a municipality to its first neighbours. Using datasets from ISTAT, GSE and ENEA, the node production and attraction of photovoltaic energy have been estimated with high accuracy. The attraction index was built using demographic data, in accordance with medium per capita energy consumption data. Moreover, the energy produced in each node could be determined using data on the installed photovoltaic power and on local solar radiation. The available energy on each node was calculated by running a distributive model assuming that the energy produced in one node which diffuses to its first neighbours is proportional to the attraction index of the latter. Therefore the available energy at each node is the sum of many contributions, coming from topological paths involving all the other nodes across the network. The availability of cross temporal data on the photovoltaic power installed on the Italian territory also make it possible to understand the evolution of the available photovoltaic energy landscape over time.","Valori, Luca;Giannuzzi, Giovanni Luca;Squartini, Tiziano;Garlaschelli, Diego;Basosi, Riccardo",54935758100;56074172600;36912065800;6603265005;7003824787
10.1002/sia.3809,11,"Laser cladding of the Ti3Al+TiB2 pre-placed alloy powder on the Ti-6Al-4V alloy in nitrogen protective atmosphere can form the Ti3Al+TiB2/TiN composite coating, which can dramatically improve the wear resistance of the Ti-6Al-4V alloy surface. In this study, the Ti3Al+TiB2/TiN composite coatings on the Ti-6Al-4V alloy have been researched by means of X-ray diffraction, SEM and energy dispersive spectrometry. It was found that there is a metallurgical combination between the Ti3Al+TiB2/TiN composite coating and the substrate. The microhardness of the Ti3Al+TiB2/TiN composite coatings were 3∼4 times higher than that of the Ti-6Al-4V alloy because of the actions of the Ti3Al+TiB2/TiN hard phases and the grain refinement strengthening. Moreover, the wear mass losses of the Ti 3Al+TiB2/TiN composite coatings were much lower than that of the substrate. © 2011 John Wiley & Sons, Ltd.","Li, J. N.;Chen, C. Z.;Cui, B. B.;Squartini, T.",36491876300;8947289900;40261156200;36912065800
10.1103/PhysRevE.84.046117,111,"The international trade network (ITN) has received renewed multidisciplinary interest due to recent advances in network theory. However, it is still unclear whether a network approach conveys additional, nontrivial information with respect to traditional international-economics analyses that describe world trade only in terms of local (first-order) properties. In this and in a companion paper, we employ a recently proposed randomization method to assess in detail the role that local properties have in shaping higher-order patterns of the ITN in all its possible representations (binary or weighted, directed or undirected, aggregated or disaggregated by commodity) and across several years. Here we show that, remarkably, the properties of all binary projections of the network can be completely traced back to the degree sequence, which is therefore maximally informative. Our results imply that explaining the observed degree sequence of the ITN, which has not received particular attention in economic theory, should instead become one the main focuses of models of trade. © 2011 American Physical Society.","Squartini, Tiziano;Fagiolo, Giorgio;Garlaschelli, Diego",36912065800;6507866198;6603265005
10.1088/1367-2630/13/8/083001,159,"In order to detect patterns in real networks, randomized graph ensembles that preserve only part of the topology of an observed network are systematically used as fundamental null models. However, the generation of them is still problematic. Existing approaches are either computationally demanding and beyond analytic control or analytically accessible but highly approximate. Here, we propose a solution to this long-standing problem by introducing a fast method that allows one to obtain expectation values and standard deviations of any topological property analytically, for any binary, weighted, directed or undirected network. Remarkably, the time required to obtain the expectation value of any property analytically across the entire graph ensemble is as short as that required to compute the same property using the adjacency matrix of the single original network. Our method reveals that the null behavior of various correlation properties is different from what was believed previously, and is highly sensitive to the particular network considered. Moreover, our approach shows that important structural properties (such as the modularity used in community detection problems) are currently based on incorrect expressions, and provides the exact quantities that should replace them. © IOP Publishing Ltd and Deutsche Physikalische Gesellschaft.","Squartini, Tiziano;Garlaschelli, Diego",36912065800;6603265005
10.1016/j.jallcom.2011.01.199,51,"Laser cladding of the Fe3Al + TiB2/Al 2O3 pre-placed alloy powder on Ti-6Al-4V alloy can form the Ti3Al/Fe3Al + TiB2/Al2O 3 ceramic layer, which can greatly increase wear resistance of titanium alloy. In this study, the Ti3Al/Fe3Al + TiB 2/Al2O3 ceramic layer has been researched by means of electron probe, X-ray diffraction, scanning electron microscope and micro-analyzer. In cladding process, Al2O3 can react with TiB2 leading to formation of amount of Ti3Al and B. This principle can be used to improve the Fe3Al + TiB2 laser cladded coating, it was found that with addition of Al2O3, the microstructure performance and micro-hardness of the coating was obviously improved due to the action of the Al-Ti-B system and hard phases. © 2011 Elsevier B.V. All rights reserved.","Li, Jianing;Chen, Chuanzhong;Lin, Zhaoqing;Squartini, Tiziano",36491876300;8947289900;57225861942;36912065800
10.1016/j.apsusc.2010.08.094,105,"Laser cladding of the Al + TiC alloy powder on Ti-6Al-4V alloy can form the Ti 3 Al/TiAl + TiC ceramic layer. In this study, TiC particle-dispersed Ti 3 Al/TiAl matrix ceramic layer on the Ti-6Al-4V alloy by laser cladding has been researched by means of X-ray diffraction, scanning electron microscope, electron probe micro-analyzer, energy dispersive spectrometer. The main difference from the earlier reports is that Ti 3 Al/TiAl has been chosen as the matrix of the composite coating. The wear resistance of the Al + 30 wt.% TiC and the Al + 40 wt.% TiC cladding layer was approximately 2 times greater than that of the Ti-6Al-4V substrate due to the reinforcement of the Ti 3 Al/TiAl + TiC hard phases. However, when the TiC mass percent was above 40 wt.%, the thermal stress value was greater than the materials yield strength limit in the ceramic layer, the microcrack was present and its wear resistance decreased. © 2010 Elsevier B.V. All rights reserved.","Li, Jianing;Chen, Chuanzhong;Squartini, Tiziano;He, Qingshan",36491876300;8947289900;36912065800;36910162100
10.1393/ncc/i2007-10244-8,2,"Neural networks can be defined in a variety of ways. Biology, informatics, mathematics, physics: each discipline gave its own definition. We will try to explain what neural networks are and why they are so useful. The paper is divided in two parts: in the first one preliminary definitions are given and general properties are illustrated. In the second part structures and dynamics of a number of networks are analyzed. © Società Italiana di Fisica.","Squartini, T.",36912065800
