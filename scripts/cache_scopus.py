import os
import sqlite3

import numpy as np
import pandas as pd

import requests


def cache_scopus():
    # read the authors list
    authors_path = os.path.join(os.path.dirname(__file__),
                                '..', 'data', 'txt', 'authors.txt')

    with open(authors_path, 'r') as file:
        authors = file.readlines()

    print(f'Found {len(authors)} authors.')

    # for each author, get the papers from scopus
    for author in authors:
        # "clean" author
        # TODO make safer conversion
        author = int(author.strip())

        # get the papers
        print(f'Processing author: {author}')
        success, papers = get_papers_by_id(author)

        # save the papers in the database
        if success:
            print(f'Saving papers to the DB.')
            save_to_db(papers)


def get_papers_by_id(author_id):
    # TODO REMOVE KEY BEFORE COMMITTING
    api_key = "TODO"

    base_url = "https://api.elsevier.com/content/search/scopus"
    headers = {
        "X-ELS-APIKey": api_key,
        "Accept": "application/json"
    }
    params = {
        "query": f"AU-ID({author_id})",
        "field": "DOI,citedby-count"
    }

    response = requests.get(base_url, headers=headers, params=params)

    success = False

    if response.status_code == 200:
        papers_raw = response.json()

        # clean

        success = True
    else:
        print("Failed to retrieve data:", response.status_code)

    return success, papers_raw


def save_to_db(papers):
    pass


# ------------------------------------------------------------

if __name__ == '__main__':
    cache_scopus()
